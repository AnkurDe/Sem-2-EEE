{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b4747482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after cleaning: (470, 16)\n",
      "Data shape after outlier removal: (379, 16)\n",
      "Top SHAP feature importances:\n",
      "DBDS            0.302830\n",
      "InterfacialV    0.175578\n",
      "Acethylene      0.076243\n",
      "Methane         0.063972\n",
      "PowerFactor     0.056725\n",
      "WaterContent    0.049989\n",
      "CO2             0.042340\n",
      "Hydrogen        0.034127\n",
      "dtype: float64\n",
      "Data shape after smoothing: (379, 10)\n"
     ]
    }
   ],
   "source": [
    "# initial cell\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import shap\n",
    "\n",
    "DATA_FILE = 'standardized_data.csv'\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "\n",
    "# Drop exact duplicates and any rows with missing values\n",
    "df = df.drop_duplicates().dropna()\n",
    "print(f\"Data shape after cleaning: {df.shape}\")\n",
    "\n",
    "# Optional: remove obvious outliers (e.g., beyond 3σ in any feature)\n",
    "# Only apply to feature columns, not targets\n",
    "feature_cols = df.columns[:-2]  # Assuming last 2 are targets\n",
    "for col in feature_cols:\n",
    "    mean, std = df[col].mean(), df[col].std()\n",
    "    df = df[(df[col] >= mean - 3*std) & (df[col] <= mean + 3*std)]\n",
    "\n",
    "print(f\"Data shape after outlier removal: {df.shape}\")\n",
    "\n",
    "# Prepare initial data splits\n",
    "X = df.drop(columns=[\"Health index\", \"Life expectation\"])\n",
    "y = df[[\"Health index\", \"Life expectation\"]]\n",
    "\n",
    "# SHAP-based feature selection\n",
    "# First, standardize for SHAP analysis\n",
    "scaler_shap = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler_shap.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Train model for SHAP analysis\n",
    "model_shap = MultiOutputRegressor(ExtraTreesRegressor(n_estimators=200, random_state=42))\n",
    "model_shap.fit(X_scaled, y)\n",
    "\n",
    "# SHAP analysis - use first estimator for feature importance\n",
    "explainer = shap.TreeExplainer(model_shap.estimators_[0])\n",
    "shap_values = explainer.shap_values(X_scaled)\n",
    "\n",
    "# Calculate feature importance based on mean absolute SHAP values\n",
    "shap_means = np.abs(shap_values).mean(0)\n",
    "shap_imports = pd.Series(shap_means, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "print(\"Top SHAP feature importances:\")\n",
    "print(shap_imports.head(8))\n",
    "\n",
    "# Select top 8 features\n",
    "top_feats = shap_imports.head(8).index.tolist()\n",
    "\n",
    "# Apply feature selection\n",
    "X_selected = X[top_feats]\n",
    "\n",
    "# Apply smoothing to selected features and targets\n",
    "to_smooth = top_feats + ['Health index', 'Life expectation']\n",
    "df_smooth = df[to_smooth].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "# Remove any remaining NaN values after smoothing\n",
    "df_smooth = df_smooth.dropna()\n",
    "\n",
    "print(f\"Data shape after smoothing: {df_smooth.shape}\")\n",
    "\n",
    "# After all preprocessing, prepare final data\n",
    "X_processed = df_smooth[top_feats]\n",
    "y_processed = df_smooth[['Health index', 'Life expectation']]\n",
    "\n",
    "# Normalize the data column-wise (final step)\n",
    "X_norm = (X_processed - X_processed.mean()) / X_processed.std()\n",
    "y_norm = (y_processed - y_processed.mean()) / y_processed.std()\n",
    "\n",
    "# Split into train and test sets (final variables)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y_norm, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8948e56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "\n",
      "Health Index:\n",
      "MSE: 0.287841\n",
      "R²: 0.684890\n",
      "MAPE: 51.151025%\n",
      "\n",
      "Life Expectation:\n",
      "MSE: 0.287135\n",
      "R²: 0.707110\n",
      "MAPE: 364.098029%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import MultiTaskLasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize and train MultiTaskLasso\n",
    "lasso = MultiTaskLasso(alpha=0.1, random_state=42)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = lasso.predict(X_test)\n",
    "\n",
    "# Denormalize predictions for evaluation\n",
    "y_std = y.std()\n",
    "y_mean = y.mean()\n",
    "y_pred_denorm = pd.DataFrame(y_pred * y_std.values + y_mean.values, \n",
    "                              columns=y.columns, \n",
    "                              index=y_test.index)\n",
    "y_test_denorm = y_test * y_std + y_mean\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test_denorm, y_pred_denorm, multioutput='raw_values')\n",
    "r2 = r2_score(y_test_denorm, y_pred_denorm, multioutput='raw_values')\n",
    "mape = np.mean(np.abs((y_test_denorm - y_pred_denorm) / y_test_denorm), axis=0) * 100\n",
    "mape = pd.Series(mape, index=y.columns)  # Ensure consistent Series with labels\n",
    "\n",
    "print(\"Model Performance:\\n\")\n",
    "print(\"Health Index:\")\n",
    "print(f\"MSE: {mse[0]:.6f}\")\n",
    "print(f\"R²: {r2[0]:.6f}\")\n",
    "print(f\"MAPE: {mape.iloc[0]:.6f}%\\n\")\n",
    "\n",
    "print(\"Life Expectation:\")\n",
    "print(f\"MSE: {mse[1]:.6f}\")\n",
    "print(f\"R²: {r2[1]:.6f}\")\n",
    "print(f\"MAPE: {mape.iloc[1]:.6f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ad744080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MultiTaskElasticNet R² values:\n",
      "Health Index R²: 0.735071\n",
      "Life Expectation R²: 0.719207\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import MultiTaskElasticNet\n",
    "\n",
    "# Fit MultiTaskElasticNet and compute R² values\n",
    "enet = MultiTaskElasticNet(alpha=0.1, random_state=42)\n",
    "enet.fit(X_train, y_train)\n",
    "y_pred_enet = enet.predict(X_test)\n",
    "from sklearn.metrics import r2_score\n",
    "r2_enet = r2_score(y_test, y_pred_enet, multioutput='raw_values')\n",
    "\n",
    "# Print R² values from MultiTaskElasticNet\n",
    "print(\"\\nMultiTaskElasticNet R² values:\")\n",
    "print(f\"Health Index R²: {r2_enet[0]:.6f}\")\n",
    "print(f\"Life Expectation R²: {r2_enet[1]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3aaed9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "Health Index - MSE: 0.134519, R²: 0.892221\n",
      "Life Expectation - MSE: 0.083594, R²: 0.917003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize RandomForestRegressor for each target\n",
    "rf_health = RandomForestRegressor(random_state=42)\n",
    "rf_life = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fit the models\n",
    "rf_health.fit(X_train, y_train[\"Health index\"])\n",
    "rf_life.fit(X_train, y_train[\"Life expectation\"])\n",
    "\n",
    "# Predict on test set\n",
    "y1_pred = rf_health.predict(X_test)\n",
    "y2_pred = rf_life.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "health_mse = mean_squared_error(y_test[\"Health index\"], y1_pred)\n",
    "health_r2 = r2_score(y_test[\"Health index\"], y1_pred)\n",
    "life_mse = mean_squared_error(y_test[\"Life expectation\"], y2_pred)\n",
    "life_r2 = r2_score(y_test[\"Life expectation\"], y2_pred)\n",
    "\n",
    "print(\"Test Set Performance:\")\n",
    "print(f\"Health Index - MSE: {health_mse:.6f}, R²: {health_r2:.6f}\")\n",
    "print(f\"Life Expectation - MSE: {life_mse:.6f}, R²: {life_r2:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dd6daccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesRegressor Testing Errors:\n",
      "Health Index: MSE = 0.103774, R² = 0.916855\n",
      "Life Expectation: MSE = 0.063640, R² = 0.936815\n"
     ]
    }
   ],
   "source": [
    "# Use already loaded X, y1, y2 from previous cells\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# Initialize and train ExtraTrees models\n",
    "et_health = ExtraTreesRegressor(random_state=42).fit(X_train, y_train[\"Health index\"])\n",
    "et_life = ExtraTreesRegressor(random_state=42).fit(X_train, y_train[\"Life expectation\"])\n",
    "\n",
    "# Predict on test data\n",
    "y1_pred_test = et_health.predict(X_test)\n",
    "y2_pred_test = et_life.predict(X_test)\n",
    "\n",
    "# Calculate testing errors\n",
    "errors_test = {\n",
    "    \"Health Index\": {\n",
    "        \"MSE\": mean_squared_error(y_test[\"Health index\"], y1_pred_test),\n",
    "        \"R²\": r2_score(y_test[\"Health index\"], y1_pred_test)\n",
    "    },\n",
    "    \"Life Expectation\": {\n",
    "        \"MSE\": mean_squared_error(y_test[\"Life expectation\"], y2_pred_test),\n",
    "        \"R²\": r2_score(y_test[\"Life expectation\"], y2_pred_test)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Print results\n",
    "print(\"ExtraTreesRegressor Testing Errors:\")\n",
    "for target, metrics in errors_test.items():\n",
    "    print(f\"{target}: MSE = {metrics['MSE']:.6f}, R² = {metrics['R²']:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e88dea66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor Testing Errors:\n",
      "Health Index: MSE = 0.146948, R² = 0.882263\n",
      "Life Expectation: MSE = 0.071934, R² = 0.928580\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Initialize Gradient Boosting models for each target\n",
    "gb_health = GradientBoostingRegressor(random_state=42)\n",
    "gb_life = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Train the models\n",
    "gb_health.fit(X_train, y_train[\"Health index\"])\n",
    "gb_life.fit(X_train, y_train[\"Life expectation\"])\n",
    "\n",
    "# Predict on test data\n",
    "y1_pred_test = gb_health.predict(X_test)\n",
    "y2_pred_test = gb_life.predict(X_test)\n",
    "\n",
    "# Calculate testing errors\n",
    "errors_test = {\n",
    "    \"Health Index\": {\n",
    "        \"MSE\": mean_squared_error(y_test[\"Health index\"], y1_pred_test),\n",
    "        \"R²\": r2_score(y_test[\"Health index\"], y1_pred_test)\n",
    "    },\n",
    "    \"Life Expectation\": {\n",
    "        \"MSE\": mean_squared_error(y_test[\"Life expectation\"], y2_pred_test),\n",
    "        \"R²\": r2_score(y_test[\"Life expectation\"], y2_pred_test)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Print results\n",
    "print(\"GradientBoostingRegressor Testing Errors:\")\n",
    "for target, metrics in errors_test.items():\n",
    "    print(f\"{target}: MSE = {metrics['MSE']:.6f}, R² = {metrics['R²']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c6d23155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Test Set Performance:\n",
      "\n",
      "Health Index:\n",
      "Test MSE: 0.147326\n",
      "Test R²: 0.881960\n",
      "\n",
      "Life Expectation:\n",
      "Test MSE: 0.077984\n",
      "Test R²: 0.922573\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Use the already split X_train, X_test, y_train, y_test from previous cells\n",
    "# Use columns from y for each target\n",
    "y_health_train = y_train[\"Health index\"]\n",
    "y_health_test = y_test[\"Health index\"]\n",
    "y_life_train = y_train[\"Life expectation\"]\n",
    "y_life_test = y_test[\"Life expectation\"]\n",
    "\n",
    "# Initialize XGBoost models\n",
    "xgb_health = xgb.XGBRegressor(random_state=42)\n",
    "xgb_life = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "# Train models\n",
    "xgb_health.fit(X_train, y_health_train)\n",
    "xgb_life.fit(X_train, y_life_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_health_pred = xgb_health.predict(X_test)\n",
    "y_life_pred = xgb_life.predict(X_test)\n",
    "\n",
    "# Calculate R² and MSE for test data\n",
    "health_test_mse = mean_squared_error(y_health_test, y_health_pred)\n",
    "health_test_r2 = r2_score(y_health_test, y_health_pred)\n",
    "\n",
    "life_test_mse = mean_squared_error(y_life_test, y_life_pred)\n",
    "life_test_r2 = r2_score(y_life_test, y_life_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"XGBoost Test Set Performance:\\n\")\n",
    "print(\"Health Index:\")\n",
    "print(f\"Test MSE: {health_test_mse:.6f}\")\n",
    "print(f\"Test R²: {health_test_r2:.6f}\\n\")\n",
    "\n",
    "print(\"Life Expectation:\")\n",
    "print(f\"Test MSE: {life_test_mse:.6f}\")\n",
    "print(f\"Test R²: {life_test_r2:.6f}\")\n",
    "\n",
    "# Model is overfitting\n",
    "# The training error is much lower than the cross-validation error\n",
    "# The model is not generalizing well to unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "39ab6ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM MultiOutputRegressor Testing Performance:\n",
      "\n",
      "Health Index:\n",
      "  Test MSE: 0.140750\n",
      "  Test R²: 0.887229\n",
      "Life Expectation:\n",
      "  Test MSE: 0.076342\n",
      "  Test R²: 0.924203\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "\n",
    "# Suppress LightGBM warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Define model with feature_fraction and bagging_fraction only\n",
    "lgb = LGBMRegressor(\n",
    "    max_depth=8,\n",
    "    num_leaves=50,\n",
    "    min_child_samples=5,\n",
    "    feature_fraction=0.7,  # preferred\n",
    "    bagging_fraction=0.7,  # preferred\n",
    "    random_state=42,\n",
    "    verbose=-1,  # suppress training logs\n",
    "    force_row_wise=True\n",
    ")\n",
    "\n",
    "multi_lgb = MultiOutputRegressor(lgb)\n",
    "\n",
    "# Train the model\n",
    "multi_lgb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_test = multi_lgb.predict(X_test)\n",
    "\n",
    "# Calculate testing errors\n",
    "test_mse = mean_squared_error(y_test, y_pred_test, multioutput='raw_values')\n",
    "test_r2 = r2_score(y_test, y_pred_test, multioutput='raw_values')\n",
    "\n",
    "# Print results\n",
    "target_names = ['Health Index', 'Life Expectation']\n",
    "print(\"LightGBM MultiOutputRegressor Testing Performance:\\n\")\n",
    "for i, name in enumerate(target_names):\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Test MSE: {test_mse[i]:.6f}\")\n",
    "    print(f\"  Test R²: {test_r2[i]:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "415a0a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Testing Performance:\n",
      "\n",
      "Health Index:\n",
      "  Test MSE: 0.178457\n",
      "  Test R²: 0.857018\n",
      "Life Expectation:\n",
      "  Test MSE: 0.063175\n",
      "  Test R²: 0.937276\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "# Initialize CatBoost with MultiRMSE objective\n",
    "cb = CatBoostRegressor(\n",
    "    iterations=500,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='MultiRMSE',\n",
    "    random_seed=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "cb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_test = cb.predict(X_test)\n",
    "\n",
    "# Calculate testing errors\n",
    "test_mse = mean_squared_error(y_test, y_pred_test, multioutput='raw_values')\n",
    "test_r2 = r2_score(y_test, y_pred_test, multioutput='raw_values')\n",
    "\n",
    "# Print results\n",
    "target_names = ['Health Index', 'Life Expectation']\n",
    "print(\"CatBoost Testing Performance:\\n\")\n",
    "for i, name in enumerate(target_names):\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Test MSE: {test_mse[i]:.6f}\")\n",
    "    print(f\"  Test R²: {test_r2[i]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a36076cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Regressor Testing Performance:\n",
      "\n",
      "Health Index:\n",
      "  Test MSE: 0.180933\n",
      "  Test R²: 0.855033\n",
      "Life Expectation:\n",
      "  Test MSE: 0.117758\n",
      "  Test R²: 0.883082\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Initialize KNN Regressor\n",
    "knn = KNeighborsRegressor(\n",
    "    n_neighbors=5,       # Number of neighbors to consider\n",
    "    weights='uniform',   # Weighting: 'uniform' or 'distance'\n",
    "    algorithm='auto',    # Algorithm: 'auto', 'ball_tree', 'kd_tree', 'brute'\n",
    "    p=2                  # Power parameter (2=euclidean distance)\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_test = knn.predict(X_test)\n",
    "\n",
    "# Calculate testing errors\n",
    "test_mse = mean_squared_error(y_test, y_pred_test, multioutput='raw_values')\n",
    "test_r2 = r2_score(y_test, y_pred_test, multioutput='raw_values')\n",
    "\n",
    "# Print results\n",
    "target_names = ['Health Index', 'Life Expectation']\n",
    "print(\"K-Nearest Neighbors Regressor Testing Performance:\\n\")\n",
    "for i, name in enumerate(target_names):\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Test MSE: {test_mse[i]:.6f}\")\n",
    "    print(f\"  Test R²: {test_r2[i]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2bfd13d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR (MultiOutputRegressor) Testing Performance:\n",
      "\n",
      "Health Index:\n",
      "  Test MSE: 0.317448\n",
      "  Test R²: 0.745656\n",
      "Life Expectation:\n",
      "  Test MSE: 0.169287\n",
      "  Test R²: 0.831921\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale features (important for SVR)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize SVR with MultiOutputRegressor\n",
    "svr = SVR(\n",
    "    kernel='rbf',        # Radial basis function kernel\n",
    "    C=1.0,              # Regularization parameter\n",
    "    epsilon=0.1,        # Epsilon in epsilon-SVR\n",
    "    gamma='scale'       # Kernel coefficient\n",
    ")\n",
    "multi_svr = MultiOutputRegressor(svr)\n",
    "\n",
    "# Train the model\n",
    "multi_svr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_test = multi_svr.predict(X_test)\n",
    "\n",
    "# Calculate testing errors\n",
    "test_mse = mean_squared_error(y_test, y_pred_test, multioutput='raw_values')\n",
    "test_r2 = r2_score(y_test, y_pred_test, multioutput='raw_values')\n",
    "\n",
    "# Print results\n",
    "target_names = ['Health Index', 'Life Expectation']\n",
    "print(\"SVR (MultiOutputRegressor) Testing Performance:\\n\")\n",
    "for i, name in enumerate(target_names):\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Test MSE: {test_mse[i]:.6f}\")\n",
    "    print(f\"  Test R²: {test_r2[i]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8fb244f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianProcessRegressor Testing Performance:\n",
      "\n",
      "Health Index:\n",
      "  Test MSE: 0.712201\n",
      "  Test R²: 0.202147\n",
      "Life Expectation:\n",
      "  Test MSE: 0.670427\n",
      "  Test R²: 0.326832\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale features (important for Gaussian Process)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define kernel for Gaussian Process\n",
    "kernel = ConstantKernel(1.0) * RBF(length_scale=1.0)\n",
    "\n",
    "# Initialize GaussianProcessRegressor\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-10,  # Added to diagonal for numerical stability\n",
    "    normalize_y=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "gp.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_test = gp.predict(X_test)\n",
    "\n",
    "# Calculate testing errors\n",
    "test_mse = mean_squared_error(y_test, y_pred_test, multioutput='raw_values')\n",
    "test_r2 = r2_score(y_test, y_pred_test, multioutput='raw_values')\n",
    "\n",
    "# Print results\n",
    "target_names = ['Health Index', 'Life Expectation']\n",
    "print(\"GaussianProcessRegressor Testing Performance:\\n\")\n",
    "for i, name in enumerate(target_names):\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Test MSE: {test_mse[i]:.6f}\")\n",
    "    print(f\"  Test R²: {test_r2[i]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "45fdb296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Regressor Testing Performance:\n",
      "\n",
      "Health Index:\n",
      "  Test MSE: 0.433814\n",
      "  Test R²: 0.514013\n",
      "Life Expectation:\n",
      "  Test MSE: 0.392680\n",
      "  Test R²: 0.605714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale features and targets (critical for neural networks)\n",
    "X_scaler = StandardScaler()\n",
    "X_scaled = X_scaler.fit_transform(X)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_scaled = y_scaler.fit_transform(y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize MLP Regressor\n",
    "mlp = MLPRegressor(\n",
    "    hidden_layer_sizes=(100, 50),  # Network architecture\n",
    "    activation='relu',            # Activation function\n",
    "    solver='adam',                # Optimization algorithm\n",
    "    alpha=0.0001,                 # L2 regularization\n",
    "    batch_size=32,                # Mini-batch size\n",
    "    learning_rate_init=0.001,     # Initial learning rate\n",
    "    max_iter=500,                 # Maximum iterations\n",
    "    random_state=42,\n",
    "    early_stopping=True,          # Stop if validation score doesn't improve\n",
    "    validation_fraction=0.1       # Fraction of training data for validation\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_test_scaled = mlp.predict(X_test)\n",
    "y_pred_test = y_scaler.inverse_transform(y_pred_test_scaled)\n",
    "y_test_original = y_scaler.inverse_transform(y_test)\n",
    "\n",
    "# Calculate testing errors\n",
    "test_mse = mean_squared_error(y_test_original, y_pred_test, multioutput='raw_values')\n",
    "test_r2 = r2_score(y_test_original, y_pred_test, multioutput='raw_values')\n",
    "\n",
    "# Print results\n",
    "target_names = ['Health Index', 'Life Expectation']\n",
    "print(\"MLP Regressor Testing Performance:\\n\")\n",
    "for i, name in enumerate(target_names):\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Test MSE: {test_mse[i]:.6f}\")\n",
    "    print(f\"  Test R²: {test_r2[i]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "734095f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegressorChain Testing Performance:\n",
      "\n",
      "Health Index:\n",
      "  Test MSE: 0.467609\n",
      "  Test R²: 0.476155\n",
      "Life Expectation:\n",
      "  Test MSE: 0.588468\n",
      "  Test R²: 0.409127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.multioutput import RegressorChain\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize RegressorChain with Ridge as the base estimator\n",
    "chain = RegressorChain(\n",
    "    base_estimator=Ridge(alpha=1.0, random_state=42),\n",
    "    order='random',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "chain.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_test = chain.predict(X_test)\n",
    "\n",
    "# Calculate testing errors\n",
    "test_mse = mean_squared_error(y_test, y_pred_test, multioutput='raw_values')\n",
    "test_r2 = r2_score(y_test, y_pred_test, multioutput='raw_values')\n",
    "\n",
    "# Print results\n",
    "target_names = ['Health Index', 'Life Expectation']\n",
    "print(\"RegressorChain Testing Performance:\\n\")\n",
    "for i, name in enumerate(target_names):\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Test MSE: {test_mse[i]:.6f}\")\n",
    "    print(f\"  Test R²: {test_r2[i]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "72d4b63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackingRegressor Testing Performance:\n",
      "\n",
      "Health Index:\n",
      "  Test MSE: 0.488228\n",
      "  Test R²: 0.453056\n",
      "Life Expectation:\n",
      "  Test MSE: 0.424154\n",
      "  Test R²: 0.574112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define base estimators\n",
    "estimators = [\n",
    "    ('svr', SVR(kernel='rbf', C=1.0, gamma='scale')),\n",
    "    ('dt', DecisionTreeRegressor(max_depth=5, random_state=42))\n",
    "]\n",
    "\n",
    "# Initialize StackingRegressor with Ridge as final estimator\n",
    "base_stack = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=Ridge(alpha=1.0),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "stack = MultiOutputRegressor(base_stack)\n",
    "\n",
    "# Train the model\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_test = stack.predict(X_test)\n",
    "\n",
    "# Calculate testing errors\n",
    "test_mse = mean_squared_error(y_test, y_pred_test, multioutput='raw_values')\n",
    "test_r2 = r2_score(y_test, y_pred_test, multioutput='raw_values')\n",
    "\n",
    "# Print results\n",
    "target_names = ['Health Index', 'Life Expectation']\n",
    "print(\"StackingRegressor Testing Performance:\\n\")\n",
    "for i, name in enumerate(target_names):\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Test MSE: {test_mse[i]:.6f}\")\n",
    "    print(f\"  Test R²: {test_r2[i]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d919f25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VotingRegressor R² values:\n",
      "Health Index R²: 0.604056\n",
      "Life Expectation R²: 0.591072\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This is a Python script to perform sklearn.ensemble.VotingRegressor analysis on a dataset -- an algorithm that involves multiple types of regressor and tree classifiers better for data which is non linear.\"\"\"\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize individual regressors\n",
    "lr = LinearRegression()\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Create the VotingRegressor\n",
    "voting_regressor = VotingRegressor(estimators=[\n",
    "    ('lr', lr),\n",
    "    ('rf', rf),\n",
    "    ('gb', gb)\n",
    "])\n",
    "\n",
    "# Train on each output separately using MultiOutputRegressor wrapper\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "\n",
    "# MultiOutputRegressor allows us to fit multiple regressors for each target\n",
    "multi_output_voting = MultiOutputRegressor(voting_regressor)\n",
    "multi_output_voting.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_vote = multi_output_voting.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_vote = mean_squared_error(y_test, y_pred_vote, multioutput='raw_values')\n",
    "r2_vote = r2_score(y_test, y_pred_vote, multioutput='raw_values')\n",
    "mape_vote = np.mean(np.abs((y_test - y_pred_vote) / y_test), axis=0) * 100\n",
    "\n",
    "mse_vote, r2_vote, mape_vote\n",
    "\n",
    "\n",
    "# R² values from VotingRegressor\n",
    "print(\"\\nVotingRegressor R² values:\")\n",
    "print(f\"Health Index R²: {r2_vote[0]:.6f}\")\n",
    "print(f\"Life Expectation R²: {r2_vote[1]:.6f}\")\n",
    "\n",
    "# Lower error than the previous model but not sufficiently low\n",
    "# The data maybe tree based,maywork with MLP Regressor\n",
    "# Might need to use neural networks\n",
    "# Might need to use Support Vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "df84942f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after cleaning: (470, 16)\n",
      "Data shape after outlier removal: (379, 16)\n",
      "Top SHAP feature importances:\n",
      "DBDS            0.302830\n",
      "InterfacialV    0.175578\n",
      "Acethylene      0.076243\n",
      "Methane         0.063972\n",
      "PowerFactor     0.056725\n",
      "WaterContent    0.049989\n",
      "CO2             0.042340\n",
      "Hydrogen        0.034127\n",
      "dtype: float64\n",
      "Data shape after smoothing: (379, 10)\n",
      "Health Index: Test MSE: 0.093767 Test R²: 0.904203\n",
      "Life Expectation: Test MSE: 0.044378 Test R²: 0.932420\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import shap\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('standardized_data.csv')\n",
    "\n",
    "# Drop exact duplicates and any rows with missing values\n",
    "df = df.drop_duplicates().dropna()\n",
    "print(f\"Data shape after cleaning: {df.shape}\")\n",
    "\n",
    "# Optional: remove obvious outliers (e.g., beyond 3σ in any feature)\n",
    "# Only apply to feature columns, not targets\n",
    "feature_cols = df.columns[:-2]  # Assuming last 2 are targets\n",
    "for col in feature_cols:\n",
    "    mean, std = df[col].mean(), df[col].std()\n",
    "    df = df[(df[col] >= mean - 3*std) & (df[col] <= mean + 3*std)]\n",
    "\n",
    "print(f\"Data shape after outlier removal: {df.shape}\")\n",
    "\n",
    "# Standardize features\n",
    "features = df.columns[:-2]\n",
    "scaler = StandardScaler()\n",
    "df[features] = scaler.fit_transform(df[features])\n",
    "\n",
    "# Prepare data for modeling\n",
    "X = df[features]\n",
    "y = df[['Health index', 'Life expectation']]\n",
    "\n",
    "# Train model with MultiOutputRegressor for proper multi-output handling\n",
    "model = MultiOutputRegressor(ExtraTreesRegressor(n_estimators=200, random_state=42))\n",
    "model.fit(X, y)\n",
    "\n",
    "# SHAP analysis\n",
    "# For MultiOutputRegressor, we need to handle each estimator separately\n",
    "explainer = shap.TreeExplainer(model.estimators_[0])  # Use first output's model\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "# Calculate feature importance based on mean absolute SHAP values\n",
    "shap_means = np.abs(shap_values).mean(0)\n",
    "shap_imports = pd.Series(shap_means, index=features).sort_values(ascending=False)\n",
    "\n",
    "print(\"Top SHAP feature importances:\")\n",
    "print(shap_imports.head(8))\n",
    "\n",
    "# Select top 8 features\n",
    "top_feats = shap_imports.head(8).index.tolist()\n",
    "\n",
    "# Apply smoothing to selected features and targets\n",
    "to_smooth = top_feats + ['Health index', 'Life expectation']\n",
    "df_smooth = df[to_smooth].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "# Remove any remaining NaN values after smoothing\n",
    "df_smooth = df_smooth.dropna()\n",
    "\n",
    "print(f\"Data shape after smoothing: {df_smooth.shape}\")\n",
    "\n",
    "# Prepare smoothed data\n",
    "X_s = df_smooth[top_feats]\n",
    "y_s = df_smooth[['Health index', 'Life expectation']]\n",
    "\n",
    "# Train-test split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_s, y_s, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model on smoothed data\n",
    "model2 = MultiOutputRegressor(ExtraTreesRegressor(n_estimators=200, random_state=42))\n",
    "model2.fit(X_tr, y_tr)\n",
    "\n",
    "# Calculate R² scores\n",
    "# For fair comparison, retrain baseline model with selected features only\n",
    "X_selected = X[top_feats]\n",
    "model_baseline = MultiOutputRegressor(ExtraTreesRegressor(n_estimators=200, random_state=42))\n",
    "model_baseline.fit(X_selected, y)\n",
    "\n",
    "r2_before = r2_score(y, model_baseline.predict(X_selected))  # Use selected features\n",
    "r2_after = r2_score(y_te, model2.predict(X_te))             # On test set\n",
    "\n",
    "# Calculate predictions\n",
    "y_pred_test = model2.predict(X_te)\n",
    "\n",
    "# Calculate MSE and R² for each target\n",
    "for i, target in enumerate(['Health Index', 'Life Expectation']):\n",
    "    mse = mean_squared_error(y_te.iloc[:, i], y_pred_test[:, i])\n",
    "    r2 = r2_score(y_te.iloc[:, i], y_pred_test[:, i])\n",
    "    print(f'{target}: Test MSE: {mse:.6f} Test R²: {r2:.6f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
